#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€çš„äººè„¸è®­ç»ƒè„šæœ¬
æ•´åˆQtç•Œé¢å’Œå‘½ä»¤è¡Œè®­ç»ƒï¼Œç¡®ä¿è®­ç»ƒæ•°æ®èƒ½æ­£ç¡®ä¿å­˜
"""

import cv2
import os
import sys
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from face_recognition.face_detector import FaceDetector
from face_recognition.face_recognizer import FaceRecognizer
from database.database_manager import DatabaseManager

class UnifiedFaceTrainer:
    """ç»Ÿä¸€çš„äººè„¸è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.face_detector = FaceDetector()
        self.face_recognizer = FaceRecognizer()
        self.db_manager = DatabaseManager()
        self.face_images_dir = "data/faces"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.face_images_dir, exist_ok=True)
    
    def face_detect_demo(self, image):
        """äººè„¸æ£€æµ‹å‡½æ•°ï¼ˆåŸºäºç”¨æˆ·ä»£ç ï¼‰"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        face_detector = cv2.CascadeClassifier("data/models/haarcascade_frontalface_default.xml")
        faces = face_detector.detectMultiScale(gray, 1.2, 6)
        
        # å¦‚æœæœªæ£€æµ‹åˆ°é¢éƒ¨ï¼Œåˆ™è¿”å›None
        if len(faces) == 0:
            return None, None
        
        # è·å–æœ€å¤§çš„äººè„¸
        largest_face = max(faces, key=lambda x: x[2] * x[3])
        (x, y, w, h) = largest_face
        
        # è¿”å›å›¾åƒçš„è„¸éƒ¨éƒ¨åˆ†
        return gray[y:y+h, x:x+w], largest_face
    
    def collect_from_directory(self, dir_path, person_name):
        """ä»ç›®å½•æ”¶é›†è®­ç»ƒæ ·æœ¬ï¼ˆåŸºäºç”¨æˆ·ä»£ç ï¼‰"""
        faces = []
        saved_images = []
        print(f"ä»ç›®å½•æ”¶é›† {person_name} çš„è®­ç»ƒæ ·æœ¬: {dir_path}")
        
        if not os.path.exists(dir_path):
            print(f"ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return faces, saved_images
        
        # åˆ›å»ºç”¨æˆ·ç›®å½•
        user_dir = os.path.join(self.face_images_dir, person_name)
        os.makedirs(user_dir, exist_ok=True)
        
        for i, file in enumerate(os.listdir(dir_path)):
            file_path = os.path.join(dir_path, file)
            if os.path.isfile(file_path):
                # è¯»å–å›¾åƒ
                img = cv2.imread(file_path)
                if img is None:
                    continue
                
                # æ£€æµ‹äººè„¸
                face, rect = self.face_detect_demo(img)
                if face is not None:
                    # ä¿å­˜æ£€æµ‹åˆ°çš„äººè„¸å›¾ç‰‡
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"{person_name}_{timestamp}_{i:03d}.jpg"
                    save_path = os.path.join(user_dir, filename)
                    cv2.imwrite(save_path, face)
                    saved_images.append(save_path)
                    
                    # é¢„å¤„ç†äººè„¸ï¼ˆè°ƒæ•´å¤§å°ï¼‰
                    processed_face = cv2.resize(face, (150, 150))
                    faces.append(processed_face)
                    print(f"æˆåŠŸå¤„ç†: {file} -> {filename}")
        
        print(f"ä»ç›®å½•æ”¶é›†åˆ° {len(faces)} ä¸ªæ ·æœ¬ï¼Œä¿å­˜äº† {len(saved_images)} å¼ å›¾ç‰‡")
        return faces, saved_images
    
    def save_to_database(self, person_name, image_paths, age=25, gender="æœªçŸ¥"):
        """ä¿å­˜ç”¨æˆ·ä¿¡æ¯å’Œäººè„¸å›¾ç‰‡åˆ°æ•°æ®åº“"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
            users = self.db_manager.get_all_users()
            user_id = None
            
            for user in users:
                if user[1] == person_name:
                    user_id = user[0]
                    break
            
            if user_id is None:
                # åˆ›å»ºæ–°ç”¨æˆ·
                user_id = self.db_manager.add_user(person_name, age, gender)
                print(f"åˆ›å»ºæ–°ç”¨æˆ·: {person_name}, ID: {user_id}")
            else:
                print(f"ç”¨æˆ·å·²å­˜åœ¨: {person_name}, ID: {user_id}")
            
            # ä¿å­˜äººè„¸å›¾ç‰‡è·¯å¾„åˆ°æ•°æ®åº“
            for image_path in image_paths:
                self.db_manager.add_face_image(user_id, image_path, person_name)
            
            print(f"è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œç”¨æˆ·ID: {user_id}")
            return user_id
            
        except Exception as e:
            print(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    def train_from_directories(self, training_data):
        """ä»å¤šä¸ªç›®å½•è®­ç»ƒæ¨¡å‹"""
        """
        training_data = [
            {"dir": "path/to/yangmi", "name": "æ¨å¹‚", "age": 30, "gender": "å¥³"},
            {"dir": "path/to/liuyifei", "name": "åˆ˜äº¦è²", "age": 35, "gender": "å¥³"}
        ]
        """
        all_faces = []
        all_labels = []
        all_names = []
        
        print("å¼€å§‹æ”¶é›†è®­ç»ƒæ•°æ®...")
        
        for data in training_data:
            dir_path = data["dir"]
            person_name = data["name"]
            age = data.get("age", 25)
            gender = data.get("gender", "æœªçŸ¥")
            
            # æ”¶é›†äººè„¸æ ·æœ¬
            faces, saved_images = self.collect_from_directory(dir_path, person_name)
            
            if len(faces) > 0:
                # ä¿å­˜åˆ°æ•°æ®åº“
                user_id = self.save_to_database(person_name, saved_images, age, gender)
                
                # æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
                all_faces.extend(faces)
                all_labels.extend([person_name] * len(faces))
                all_names.append(person_name)
                
                print(f"{person_name}: {len(faces)} ä¸ªæ ·æœ¬")
            else:
                print(f"è­¦å‘Š: {person_name} æ²¡æœ‰æ”¶é›†åˆ°æœ‰æ•ˆæ ·æœ¬")
        
        if len(all_faces) == 0:
            print("æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•è®­ç»ƒæ ·æœ¬ï¼")
            return False
        
        print(f"\næ€»å…±æ”¶é›†åˆ° {len(all_faces)} ä¸ªæ ·æœ¬ï¼Œ{len(all_names)} ä¸ªç”¨æˆ·")
        
        # åˆ›å»ºæ ‡ç­¾æ˜ å°„
        unique_names = list(set(all_labels))
        name_to_id = {name: i for i, name in enumerate(unique_names)}
        
        # è½¬æ¢æ ‡ç­¾ä¸ºæ•°å­—ID
        numeric_labels = [name_to_id[name] for name in all_labels]
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        images = np.array(all_faces)
        labels = np.array(numeric_labels)
        
        print(f"å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        print(f"å›¾åƒæ•°é‡: {len(images)}, æ ‡ç­¾æ•°é‡: {len(labels)}")
        print(f"æ ‡ç­¾æ˜ å°„: {name_to_id}")
        
        # è®­ç»ƒæ¨¡å‹
        try:
            recognizer = cv2.face.LBPHFaceRecognizer_create()
            recognizer.train(images, labels)
            
            # ä¿å­˜æ¨¡å‹
            model_path = "data/models/face_recognizer.yml"
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            recognizer.write(model_path)
            
            # ä¿å­˜æ ‡ç­¾æ˜ å°„
            import pickle
            label_map_path = model_path.replace('.yml', '_labels.pkl')
            label_data = {
                'name_to_id': name_to_id,
                'id_to_name': {i: name for name, i in name_to_id.items()}
            }
            with open(label_map_path, 'wb') as f:
                pickle.dump(label_data, f)
            
            print(f"âœ… è®­ç»ƒå®Œæˆï¼")
            print(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")
            print(f"æ ‡ç­¾æ˜ å°„å·²ä¿å­˜: {label_map_path}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def train_from_camera(self, person_name, num_samples=20):
        """ä»æ‘„åƒå¤´è®­ç»ƒæ¨¡å‹"""
        print(f"å¼€å§‹ä»æ‘„åƒå¤´æ”¶é›† {person_name} çš„è®­ç»ƒæ ·æœ¬...")
        
        # å¯åŠ¨æ‘„åƒå¤´
        camera = cv2.VideoCapture(0)
        if not camera.isOpened():
            print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return False
        
        samples = []
        saved_images = []
        
        try:
            for i in range(num_samples):
                ret, frame = camera.read()
                if not ret:
                    continue
                
                # æ£€æµ‹äººè„¸
                faces = self.face_detector.detect_faces(frame)
                
                if len(faces) > 0:
                    # è·å–æœ€å¤§äººè„¸
                    largest_face = max(faces, key=lambda x: x[2] * x[3])
                    x, y, w, h = largest_face
                    
                    # æå–äººè„¸åŒºåŸŸ
                    face_roi = frame[y:y+h, x:x+w]
                    
                    # ä¿å­˜äººè„¸å›¾ç‰‡
                    saved_path = self.save_face_image(face_roi, person_name, i)
                    saved_images.append(saved_path)
                    
                    # é¢„å¤„ç†äººè„¸
                    processed_face = cv2.resize(face_roi, (150, 150))
                    samples.append(processed_face)
                    
                    print(f"æ ·æœ¬ {i+1}/{num_samples} å·²é‡‡é›†")
                
                # ç­‰å¾…ä¸€ä¸‹
                cv2.waitKey(100)
            
            camera.release()
            
            if len(samples) > 0:
                # ä¿å­˜åˆ°æ•°æ®åº“
                user_id = self.save_to_database(person_name, saved_images)
                
                # è®­ç»ƒæ¨¡å‹
                return self.train_single_person(person_name, samples)
            else:
                print("æ²¡æœ‰é‡‡é›†åˆ°æœ‰æ•ˆæ ·æœ¬")
                return False
                
        except Exception as e:
            print(f"æ‘„åƒå¤´è®­ç»ƒå¤±è´¥: {e}")
            camera.release()
            return False
    
    def save_face_image(self, face_image, person_name, index):
        """ä¿å­˜äººè„¸å›¾ç‰‡åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        # åˆ›å»ºç”¨æˆ·ç›®å½•
        user_dir = os.path.join(self.face_images_dir, person_name)
        os.makedirs(user_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{person_name}_{timestamp}_{index:03d}.jpg"
        filepath = os.path.join(user_dir, filename)
        
        # ä¿å­˜å›¾ç‰‡
        cv2.imwrite(filepath, face_image)
        print(f"ä¿å­˜äººè„¸å›¾ç‰‡: {filepath}")
        
        return filepath
    
    def train_single_person(self, person_name, samples):
        """è®­ç»ƒå•ä¸ªäººå‘˜çš„æ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒ {person_name} çš„è¯†åˆ«æ¨¡å‹...")
        
        # æ¸…ç©ºä¹‹å‰çš„è®­ç»ƒæ•°æ®
        self.face_recognizer.clear_training_data()
        
        # æ·»åŠ æ‰€æœ‰æ ·æœ¬
        for sample in samples:
            self.face_recognizer.add_training_sample(sample, person_name)
        
        # è®­ç»ƒæ¨¡å‹
        success = self.face_recognizer.train()
        
        if success:
            print(f"{person_name} è®­ç»ƒå®Œæˆï¼")
        else:
            print(f"{person_name} è®­ç»ƒå¤±è´¥ï¼")
        
        return success

def main():
    print("=== ç»Ÿä¸€çš„äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒç¨‹åº ===")
    print("æ”¯æŒä»ç›®å½•å’Œæ‘„åƒå¤´è®­ç»ƒï¼Œç¡®ä¿æ•°æ®æŒä¹…åŒ–")
    
    trainer = UnifiedFaceTrainer()
    
    print("\nè¯·é€‰æ‹©è®­ç»ƒæ–¹å¼:")
    print("1. ä»ç›®å½•è®­ç»ƒï¼ˆæ¨èï¼ŒåŸºäºç”¨æˆ·ä»£ç é€»è¾‘ï¼‰")
    print("2. ä»æ‘„åƒå¤´è®­ç»ƒ")
    print("3. æŸ¥çœ‹ç°æœ‰ç”¨æˆ·")
    
    choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice == "1":
        # ä»ç›®å½•è®­ç»ƒ
        training_data = []
        
        while True:
            dir_path = input("è¯·è¾“å…¥ç”¨æˆ·å›¾ç‰‡ç›®å½•è·¯å¾„: ").strip()
            if not dir_path:
                break
                
            person_name = input("è¯·è¾“å…¥ç”¨æˆ·å§“å: ").strip()
            if not person_name:
                break
                
            age = int(input("è¯·è¾“å…¥ç”¨æˆ·å¹´é¾„ (é»˜è®¤25): ").strip() or "25")
            gender = input("è¯·è¾“å…¥ç”¨æˆ·æ€§åˆ« (ç”·/å¥³/æœªçŸ¥): ").strip() or "æœªçŸ¥"
            
            training_data.append({
                "dir": dir_path,
                "name": person_name,
                "age": age,
                "gender": gender
            })
            
            more = input("æ˜¯å¦æ·»åŠ æ›´å¤šç”¨æˆ·? (y/n): ").strip().lower()
            if more != 'y':
                break
        
        if training_data:
            success = trainer.train_from_directories(training_data)
            if success:
                print("\nğŸ‰ è®­ç»ƒæˆåŠŸï¼ç°åœ¨å¯ä»¥è¿è¡Œä¸»ç¨‹åºè¿›è¡Œäººè„¸è¯†åˆ«äº†")
            else:
                print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        else:
            print("æ²¡æœ‰è¾“å…¥è®­ç»ƒæ•°æ®")
    
    elif choice == "2":
        # ä»æ‘„åƒå¤´è®­ç»ƒ
        person_name = input("è¯·è¾“å…¥ç”¨æˆ·å§“å: ").strip()
        if person_name:
            num_samples = int(input("è¯·è¾“å…¥æ ·æœ¬æ•°é‡ (é»˜è®¤20): ").strip() or "20")
            success = trainer.train_from_camera(person_name, num_samples)
            if success:
                print("\nğŸ‰ è®­ç»ƒæˆåŠŸï¼ç°åœ¨å¯ä»¥è¿è¡Œä¸»ç¨‹åºè¿›è¡Œäººè„¸è¯†åˆ«äº†")
            else:
                print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        else:
            print("å§“åä¸èƒ½ä¸ºç©º")
    
    elif choice == "3":
        # æŸ¥çœ‹ç°æœ‰ç”¨æˆ·
        users = trainer.db_manager.get_all_users()
        if users:
            print("\nç°æœ‰ç”¨æˆ·:")
            for user in users:
                print(f"ID: {user[0]}, å§“å: {user[1]}, å¹´é¾„: {user[2]}, æ€§åˆ«: {user[3]}")
                
                # è·å–ç”¨æˆ·çš„äººè„¸å›¾ç‰‡
                face_images = trainer.db_manager.get_user_face_images(user[0])
                print(f"  äººè„¸å›¾ç‰‡æ•°é‡: {len(face_images)}")
        else:
            print("æ²¡æœ‰ç°æœ‰ç”¨æˆ·")
    
    else:
        print("æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()